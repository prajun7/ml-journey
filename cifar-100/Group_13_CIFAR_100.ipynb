{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40ea3f9f-5eda-4558-abbf-d6f6ce85d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "TensorFlow Version: 2.16.2\n",
      "Keras Version: 3.9.0\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU memory growth configured.\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow, Keras components, and other utilities.\n",
    "# - tensorflow as tf: The core TensorFlow library.\n",
    "# - tensorflow.keras : TensorFlow's high-level API for building and training models.\n",
    "# - layers: Module containing standard neural network layers (Conv2D, Dense, etc.).\n",
    "# - models: Module for creating models (Sequential, Functional API).\n",
    "# - datasets: Module containing built-in datasets like CIFAR-100.\n",
    "# - optimizers: Module containing optimization algorithms (Adam, SGD, etc.).\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, datasets, optimizers, losses\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Suppress TensorFlow informational messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "# Check for GPU availability\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"GPU available: {gpu_devices}\")\n",
    "    # Optional: Configure GPU memory growth to avoid allocating all memory at once\n",
    "    try:\n",
    "        for gpu in gpu_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth configured.\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"GPU not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b2b75992-bdfe-4ec1-afee-63afe43337e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Batch Size: 64\n",
      "  Learning Rate: 0.001\n",
      "  Number of Epochs: 100\n",
      "  Number of Classes: 100\n",
      "  Input Shape: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Hyperparameters\n",
    "# - BATCH_SIZE: Number of images processed in one training step.\n",
    "# - LEARNING_RATE: Controls the step size during optimization.\n",
    "# - NUM_EPOCHS: How many times the entire training dataset is passed through the model.\n",
    "# - NUM_CLASSES: CIFAR-100 has 100 distinct image categories.\n",
    "# - INPUT_SHAPE: The dimensions of each input image (Height, Width, Channels).\n",
    "# - L2_LAMBDA\n",
    "\n",
    "BATCH_SIZE = 64          # Number of images per batch\n",
    "LEARNING_RATE = 0.001    # Learning rate for the optimizer\n",
    "NUM_EPOCHS = 100         # Number of times to iterate over the entire dataset\n",
    "NUM_CLASSES = 100        # CIFAR-100 has 100 classes\n",
    "INPUT_SHAPE = (32, 32, 3) # CIFAR images are 32x32 pixels with 3 color channels (RGB)\n",
    "L2_LAMBDA = 1e-3 # Define L2 regularization strength\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Number of Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Number of Classes: {NUM_CLASSES}\")\n",
    "print(f\"  Input Shape: {INPUT_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c6deb9c-595f-4005-9acc-e05e702f7701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-100 dataset...\n",
      "Dataset loaded successfully.\n",
      "  x_train shape: (50000, 32, 32, 3)\n",
      "  y_train shape: (50000, 1)\n",
      "  x_test shape: (10000, 32, 32, 3)\n",
      "  y_test shape: (10000, 1)\n",
      "  Number of training samples: 50000\n",
      "  Number of test samples: 10000\n",
      "  Image data type: uint8\n",
      "  Label data type: int64\n",
      "  Min/Max pixel values: 0/255\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset directly using `tf.keras.datasets.cifar100`.\n",
    "# This function returns NumPy arrays for training and testing images and labels.\n",
    "# - Images (`x_train`, `x_test`) are NumPy arrays of shape (num_samples, 32, 32, 3) with pixel values in [0, 255].\n",
    "# - Labels (`y_train`, `y_test`) are NumPy arrays of shape (num_samples, 1) containing integer labels from 0 to 99.\n",
    "\n",
    "print(\"Loading CIFAR-100 dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(f\"  x_train shape: {x_train.shape}\") # (50000, 32, 32, 3)\n",
    "# x_train holds 50,000 images. Each of those 50,000 images is a 32x32 grid of pixels.  \n",
    "# And at each of those 32x32 pixel locations, there are 3 values representing the \n",
    "# Red, Green, and Blue color components of that pixel.\n",
    "\n",
    "print(f\"  y_train shape: {y_train.shape}\") # (50000, 1)\n",
    "print(f\"  x_test shape: {x_test.shape}\")   # (10000, 32, 32, 3)\n",
    "print(f\"  y_test shape: {y_test.shape}\")   # (10000, 1)\n",
    "print(f\"  Number of training samples: {x_train.shape[0]}\")\n",
    "print(f\"  Number of test samples: {x_test.shape[0]}\")\n",
    "print(f\"  Image data type: {x_train.dtype}\") # uint8\n",
    "print(f\"  Label data type: {y_train.dtype}\") # int64\n",
    "print(f\"  Min/Max pixel values: {x_train.min()}/{x_train.max()}\") # 0/255\n",
    "\n",
    "# # Print the first 2 rows of x_train (image data)\n",
    "# print(\"\\nFirst 2 rows of x_train (image data):\")\n",
    "# print(x_train[:2])  # Print the first 2 image arrays.\n",
    "\n",
    "# # Print the first 2 rows of y_train (labels)\n",
    "# print(\"\\nFirst 2 rows of y_train (labels):\")\n",
    "# print(y_train[:2])\n",
    "\n",
    "# # Print the first 2 rows of x_test (image data)\n",
    "# print(\"\\nFirst 5 rows of x_test (image data):\")\n",
    "# print(x_test[:2]) # Print the first 2 image arrays.\n",
    "\n",
    "# # Print the first 2 rows of y_test (labels)\n",
    "# print(\"\\nFirst 2 rows of y_test (labels):\")\n",
    "# print(y_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c4ee4738-df3b-4a32-b0b0-fc7729650c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x_train data type after conversion: float32\n",
      "  Min/Max pixel values after normalization: 0.0/1.0\n",
      "  y_train shape remains: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training:\n",
    "# - Convert Image Type: Change image data type from `uint8` to `float32` for calculations.\n",
    "# - Normalize Pixels: Scale pixel values from the range [0, 255] to [0, 1]. This helps stabilize training. Alternatively, you could scale to [-1, 1] by dividing by 127.5 and subtracting 1.\n",
    "# - Labels: The labels are already integers (0-99), which is the format expected by `SparseCategoricalCrossentropy` loss. No changes needed for `y_train`, `y_test`.\n",
    "\n",
    "# Convert image data types to float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "print(f\"  x_train data type after conversion: {x_train.dtype}\") # float32\n",
    "print(f\"  Min/Max pixel values after normalization: {x_train.min():.1f}/{x_train.max():.1f}\") # 0.0/1.0\n",
    "\n",
    "# Labels y_train and y_test remain as integer arrays of shape (N, 1)\n",
    "print(f\"  y_train shape remains: {y_train.shape}\")\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\", input_shape=INPUT_SHAPE),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "# Apply augmentation ONLY to the training data\n",
    "# Apply augmentation within the tf.data pipeline\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(x_train))\\\n",
    "                             .batch(BATCH_SIZE)\\\n",
    "                             .map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                             .prefetch(tf.data.AUTOTUNE) # Add prefetching\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\\\n",
    "                           .prefetch(tf.data.AUTOTUNE) # Add prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4b038846-c400-425a-9daf-aafa7fbd6095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining the Keras Sequential model (with Batch Norm, L2, Softmax output)...\n",
      "Model defined successfully with Batch Norm, L2, and Softmax output.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_36 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_38 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_39 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m51,300\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,196,580</span> (4.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,196,580\u001b[0m (4.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,195,108</span> (4.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,195,108\u001b[0m (4.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building the CNN using the `keras.Sequential` model, stacking layers linearly.\n",
    "# - input_shape: Specified in the first layer.\n",
    "# - layers.Conv2D: 2D convolution layer.\n",
    "# - layers.MaxPooling2D: Max pooling layer.\n",
    "# - layers.Flatten: Converts 3D features to 1D vector.\n",
    "# - layers.Dense: Fully connected layer.\n",
    "# - layers.Dropout: Applies dropout regularization.\n",
    "# - Final Dense Layer: Has `NUM_CLASSES` units and activation='softmax'. This makes the model output probabilities for each class.\n",
    "\n",
    "print(f\"Defining the Keras Sequential model (with Batch Norm, L2, Softmax output)...\")\n",
    "\n",
    "model = models.Sequential([\n",
    "    # Input Layer shape is defined in the first Conv2D layer\n",
    "    # Block 1\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), padding='same',\n",
    "                  kernel_regularizer=l2(L2_LAMBDA), input_shape=INPUT_SHAPE), # Removed activation, added regularizer\n",
    "    layers.BatchNormalization(), \n",
    "    layers.Activation('relu'),   \n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Output shape: (None, 16, 16, 32)\n",
    "\n",
    "    # Block 2\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='same',\n",
    "                  kernel_regularizer=l2(L2_LAMBDA)), # Removed activation, added regularizer\n",
    "    layers.BatchNormalization(), # Added Batch Norm\n",
    "    layers.Activation('relu'),   # Added separate Activation\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    # Output shape: (None, 8, 8, 64)\n",
    "\n",
    "    # Block 3\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='same',\n",
    "                  kernel_regularizer=l2(L2_LAMBDA)), # Removed activation, added regularizer\n",
    "    layers.BatchNormalization(), # Added Batch Norm\n",
    "    layers.Activation('relu'),   # Added separate Activation\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Output shape: (None, 4, 4, 128)\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.Flatten(),\n",
    "    # Output shape: (None, 4*4*128 = 2048)\n",
    "    layers.Dense(512, kernel_regularizer=l2(L2_LAMBDA)), # Removed activation, added regularizer\n",
    "    layers.BatchNormalization(), # Added Batch Norm\n",
    "    layers.Activation('relu'),   # Added separate Activation\n",
    "    layers.Dropout(0.5), # Dropout for regularization (keep after activation)\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax') # Output layer with Softmax activation!\n",
    "])\n",
    "\n",
    "print(\"Model defined successfully with Batch Norm, L2, and Softmax output.\")\n",
    "\n",
    "# Print a summary of the model's layers and parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ea7ccd4e-6530-4f7b-b1e1-6ce017e93047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Configuring the model for training.\n",
    "# - optimizer: Adam optimizer.\n",
    "# - loss: The loss function.\n",
    "# - SparseCategoricalCrossentropy: Used for multi-class classification with integer labels (0-99).\n",
    "# - metrics: [accuracy] to monitor classification accuracy.\n",
    "\n",
    "initial_learning_rate = LEARNING_RATE \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps= (len(x_train) // BATCH_SIZE) * 5, # Decay every 5 epochs approx\n",
    "    decay_rate=0.9, # Decay factor\n",
    "    staircase=True)\n",
    "\n",
    "# Applying the schedule in the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule) # Pass schedule here\n",
    "\n",
    "# Define the loss function suitable for probability outputs from Softmax\n",
    "# Use SparseCategoricalCrossentropy because labels are integers (0-99)\n",
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "print(\"Model compiled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0eed3c0b-c25c-4d94-9a16-2e99a3c57b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 100 epochs...\n",
      "Epoch 1/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.1329 - loss: 3.9995 - val_accuracy: 0.2804 - val_loss: 3.0557\n",
      "Epoch 2/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.3380 - loss: 2.7535 - val_accuracy: 0.3573 - val_loss: 2.6749\n",
      "Epoch 3/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.4173 - loss: 2.4153 - val_accuracy: 0.2503 - val_loss: 3.5166\n",
      "Epoch 4/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.4608 - loss: 2.2255 - val_accuracy: 0.4089 - val_loss: 2.5295\n",
      "Epoch 5/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.5086 - loss: 2.0531 - val_accuracy: 0.4083 - val_loss: 2.5436\n",
      "Epoch 6/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.5487 - loss: 1.9165 - val_accuracy: 0.4305 - val_loss: 2.5387\n",
      "Epoch 7/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.5816 - loss: 1.8058 - val_accuracy: 0.4704 - val_loss: 2.4177\n",
      "Epoch 8/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.6138 - loss: 1.7096 - val_accuracy: 0.4464 - val_loss: 2.5625\n",
      "Epoch 9/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.6439 - loss: 1.6271 - val_accuracy: 0.4448 - val_loss: 2.5939\n",
      "Epoch 10/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.6764 - loss: 1.5196 - val_accuracy: 0.4407 - val_loss: 2.6385\n",
      "Epoch 11/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.6942 - loss: 1.4773 - val_accuracy: 0.4595 - val_loss: 2.6675\n",
      "Epoch 12/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 47ms/step - accuracy: 0.7153 - loss: 1.4164 - val_accuracy: 0.4487 - val_loss: 2.7998\n",
      "Epoch 13/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - accuracy: 0.7308 - loss: 1.3706 - val_accuracy: 0.4690 - val_loss: 2.7274\n",
      "Epoch 14/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.7536 - loss: 1.3182 - val_accuracy: 0.4711 - val_loss: 2.7893\n",
      "Epoch 15/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7685 - loss: 1.2827 - val_accuracy: 0.4686 - val_loss: 2.7951\n",
      "Epoch 16/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7768 - loss: 1.2683 - val_accuracy: 0.4667 - val_loss: 2.8897\n",
      "Epoch 17/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7831 - loss: 1.2590 - val_accuracy: 0.3404 - val_loss: 4.5845\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Training the model using the `model.fit()` method.\n",
    "\n",
    "print(f\"\\nStarting training for {NUM_EPOCHS} epochs...\")\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=test_dataset, # Evaluate on test set after each epoch\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "deb96a12-07e0-4b6a-ba73-c3846ccf7e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test dataset...\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4725 - loss: 2.4133 \n",
      "\n",
      "Test Loss: 2.4177\n",
      "Test Accuracy: 47.04%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the trained model's performance on the test dataset using `model.evaluate()`.\n",
    "# - Pass the test data (`test_dataset`).\n",
    "# - It returns the final loss and metric values (e.g., accuracy) calculated on the test set.\n",
    "\n",
    "# %%\n",
    "print(\"\\nEvaluating the model on the test dataset...\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(\n",
    "    test_dataset, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010a9ea-1ce3-4c24-a912-5367616fd98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_ml_research]",
   "language": "python",
   "name": "conda-env-env_ml_research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
